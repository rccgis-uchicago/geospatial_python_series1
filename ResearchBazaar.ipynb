{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Bazaar - UW Madison, 2024\n",
    "\n",
    "## Getting Started with Python for Analyzing Large Climate and Satellite Data\n",
    "\n",
    "### Instructors:\n",
    "\n",
    "- Hamid Dashti (dashtiahanga@wisc.edu)\n",
    "- Hangkai You\n",
    "- Fujiang Ji\n",
    "- Min Chen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands\n",
    "\n",
    "- `Shift` + `Enter`: Run and move to the next cell.\n",
    "- `Ctrl` + `Enter`: Run the cell in place.\n",
    "- `Alt` + `Enter`: Run and insert a new cell below.\n",
    "- To delete a cell: Press `esc` to enter command mode, then press `cmd`+`m`+`d`.\n",
    "- To insert a new cell below: Press `esc` then `b`.\n",
    "- To insert a new cell above: Press `esc` then `a`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "\n",
    "**First Half:**\n",
    "\n",
    "- **Introduction to xarray:**\n",
    "  - Data exploration\n",
    "  - Indexing\n",
    "- **Visualizing data with xarray:**\n",
    "\n",
    "  - Static plots\n",
    "  - Interactive plotting\n",
    "\n",
    "- **Computation with Xarray:**\n",
    "\n",
    "  - Built-in functions\n",
    "  - Costume functions\n",
    "\n",
    "  **End with and exercise**\n",
    "\n",
    "**Second Half:**\n",
    "\n",
    "- **Scaling computations with Dask:**\n",
    "  - Handling out-of-memory (large) datasets\n",
    "  - Parallel programming\n",
    "- **Accessing Cloud-Based Data Catalogs:**\n",
    "  - Searching Earth Engine and Planetary Computer data (explore a STAC Catalog)\n",
    "  - Integrating cloud data into xarray workflows\n",
    "\n",
    "If time allows:\n",
    "\n",
    "- **Running Dask on HPC/HTC (Requires CHTC accounts):**\n",
    "  - Setting up Dask on UW HPC using vscode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Geospatial Data Formats for Climate and Satellite Data**\n",
    "\n",
    "## Key Formats\n",
    "\n",
    "Common geospatial file formats frequently used for climate and satellite data:\n",
    "\n",
    "### NetCDF (Network Common Data Form; <u>Our focus today</u>)\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Storing and sharing multidimensional scientific array-based data with comprehensive metadata.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Self-describing with rich metadata for efficient algorithm development.\n",
    "- Scalable for efficient access to subsets of large datasets, even remotely.\n",
    "- Appendable for data addition without structure redefinition.\n",
    "- Sharable with support for multi-user access.\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "- Gridded climate data\n",
    "- Satellite images\n",
    "- Earth system model outputs\n",
    "\n",
    "**CF Conventions (Climate and Forecast):**\n",
    "\n",
    "- Standardized metadata for self-description and interoperability.\n",
    "- Ensures variables have associated descriptions, physical units, and spatiotemporal coordinates.\n",
    "- Enables software tools to work effectively with minimal user intervention.\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [NetCDF Website](https://www.unidata.ucar.edu/software/netcdf/)\n",
    "- [CF Conventions](http://cfconventions.org/)\n",
    "\n",
    "### HDF5 (Hierarchical Data Format version 5)\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Storing complex heterogeneous datasets.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Hierarchical data organization with groups and datasets.\n",
    "- Self-describing with metadata within the file.\n",
    "- Multiple data type support (integers, floats, strings, complex numbers).\n",
    "- Chunking and compression for efficient storage and access.\n",
    "- Large file and dataset support (terabytes to petabytes).\n",
    "- Parallel processing capabilities.\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "- Many satellite data (e.g. MODIS) is HDF5.\n",
    "- Earth system model outputs.\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [HDF5 Website](https://www.hdfgroup.org/solutions/hdf5/)\n",
    "\n",
    "### Zarr\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "- Efficient parallel processing and cloud storage of large datasets.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Stores data in chunks across multiple files. Makes reading and writing large datasets faster.\n",
    "- Optimized for high-performance computing (HPC), high-throughput computing (HTC), and cloud environments.\n",
    "\n",
    "**Common Applications:**\n",
    "\n",
    "- Large-scale scientific datasets\n",
    "- Cloud-based data analysis\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [Zarr Website](https://zarr.dev/)\n",
    "\n",
    "### STAC (SpatioTemporal Asset Catalog)\n",
    "\n",
    "**Purpose:**:\n",
    "\n",
    "- Simplify search and discovery of geospatial data across different providers and platforms.\n",
    "- Enable interoperability between various tools and applications working with geospatial data.\n",
    "- Facilitate easier cloud storage and access for large datasets.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "- Uses JSON files to describe assets, providing information like location, time, data type, metadata, and availability.\n",
    "- Flexible and extensible, allowing customization for specific data types and needs.\n",
    "\n",
    "**Links:**\n",
    "\n",
    "- [STAC Website](https://stacspec.org/en)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Xarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Xarray](https://docs.xarray.dev/en/stable/): Handling NetCDF\n",
    "\n",
    "Xarray introduces labels in the form of dimensions, coordinates and attributes on top of raw NumPy-like multidimensional arrays.\n",
    "\n",
    "Most scientific data are multidimensional arrays. We can add labels to this matrices so we can make them easier to work with.\n",
    "\n",
    "The [Pandas](https://pandas.pydata.org/) is a powerful Python package for this purpose but its limitted to 2-dimensional (e.g. tablular) data.\n",
    "\n",
    "You can think of xarray as a generalized version of Pandas that can handle n-dimensional data.\n",
    "\n",
    "With Xarray, we can read, write and process netcdf files.\n",
    "\n",
    "![Dataset Diagram](./xarray.webp)\n",
    "\n",
    "Some key terminology:\n",
    "\n",
    "- **DataArray**: A labeled multi-dimensional array.\n",
    "- **Dataset**: A collection of DataArray objects.\n",
    "- **Variable**: A NetCDF-like variable consisting of dimensions, data, and attributes which describe a single array.\n",
    "- **Dimension**: The name of the axis of the data. E.g. in math we say 'x' dimension to describe values on x axis, in climate data we can say 'time' dimension to describe that data has a temporal aspect.\n",
    "- **Coordinates**: An array that labels a dimension or set of dimensions of another DataArray. E.g. for 'x' axis in math we have (0,1,2,...), similarly we can have labels for the latitude dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download Data\n",
    "\n",
    "We are going to download the monthly mean of air (2m) temprature from 1948/01-2023/12.\n",
    "\n",
    "The data is provided by [NOAA Physical Sciences Laboratory](https://psl.noaa.gov/data/gridded/), the GHCN CAMS product (declaimer: I'm not sure how good or bad this data is, our purpose is just learning handling such a file).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these libraries are not installed in Google Colab by default. So we have to install them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the following libraries:\n",
    "!pip install cartopy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data, it may take less than a minute. Let me know if its more than that, I can hand it to you by USB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Download the data\n",
    "url = f\"https://downloads.psl.noaa.gov/Datasets/ghcncams/air.mon.mean.nc\"\n",
    "savename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open the data and explore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the air temprature Dataset\n",
    "ds = xr.open_dataset(savename)\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the air temperature data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the air temprature DataArray\n",
    "ta = ds[\"air\"]\n",
    "ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we already know that there is only one variable in the dataset, we can use the shortcut to load the data using `xr.open_dataarray()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = xr.open_dataarray(savename)\n",
    "ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the values of the air temprature DataArray as numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta.values\n",
    "data = ta.data\n",
    "print(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dimensions names. Note its only names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the coordinates. Note these are array of labels (lat/lon values, timestamps).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can extract the time, latitude, and longitude coordinates as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.coords[\"time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metadata (attribute):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.attrs\n",
    "# Similar to coordinates, you can access the attributes of a DataArray using the .attrs[\"\"]:\n",
    "# print(ta.attrs['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many functions used in numpy can be used here as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example get the shape of the data\n",
    "ta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and selecting data and simple plotting\n",
    "\n",
    "Labeling data (as xarray does) make indexing and selecting data very flexible and intuitive. We can index data based on position or labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index like python standard method `[]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example index data at the first time step and all latitudes and longitudes.\n",
    "ta[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save NetCDF files to the disk using `to_netcdf()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ta.to_netcdf(\"ta.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Practice: Index Data Inclusive of the Upper Hemisphere for Time=100, plot it and Save to Disk**\n",
    "\n",
    "_Hint: Utilize functions like `range()` or `np.arange()` for efficient indexing. For plotting extract data using `.values` and plot it using `plt.imshow()`_\n",
    "\n",
    "_Bonus: If you have other software, such as QGIS, installed on your computer, try opening the exported file to explore its contents._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first find what is the index for latitude from 0 to 90\n",
    "# print(ta.coords[\"lat\"][0:180])\n",
    "upper_hemsphere = ta[100, 0:180, :]\n",
    "plt.imshow(upper_hemsphere.values, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index with dimension names using `isel()` and `sel` methods. Much more intuitive!\n",
    "\n",
    "- `isel()` is integer-based selection much like `iloc()` in `pandas` or python's `[]`.\n",
    "- `sel()` is label-based selection like `'loc()` in pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do same thing along lat and lon dimensions\n",
    "data_isel = ta.isel(time=range(0, 12))\n",
    "data_isel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sel = ta.sel(time=[\"2023-08-01\", \"2023-09-01\"])\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select a range of labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.sel(time=slice(\"1984-01-01\", \"1984-12-01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearest neighbor selection. Sometime we don' know the exact index (e.g. latitude), so we use nearest neighbor method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Here we want find closes air temperature to a specific lat and lon.\n",
    "\n",
    "But the longitude of this file starts from 0 on its most left to 360 on its most right. Lets make it from -180 to 180.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing longitude\n",
    "# We will soon see more on basic calculations like below:\n",
    "ta.coords[\"lon\"] = (ta.coords[\"lon\"] + 180) % 360 - 180\n",
    "ta = ta.sortby(ta.lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the nearest neighbor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = ta.sel(lat=43, lon=89, method=\"nearest\")\n",
    "plt.plot(nearest_neighbor.values, \"-\")\n",
    "nearest_neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Mask with `where()`\n",
    "\n",
    "The `where()` can come handy in many many situations.\n",
    "\n",
    "For example, we can tell where in the world temperature was above/below a certain degree, create masks, find missing data and many other applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ta.sel(time=\"2023-05-01\")\n",
    "da_cold = da.where(da < 273.15)\n",
    "plt.imshow(da_cold.values, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace the masked regions and replace it with desired data.\n",
    "\n",
    "In the code below we say find grids where temp is less than 273.15 K and replace them with temp=500 K (just because we can!), and for other region keep the original value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the below zero values with 100 (just for the sake of example)\n",
    "da_hot = xr.where(da < 273.15, 500, da)\n",
    "plt.imshow(da_hot.values, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can replace it with other DataArrays...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tmp = xr.where(da < 273.15, ta.sel(time=\"1985-08-01\"), da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One dimensional plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply use the `plot()` method to plot the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.sel(time=slice(\"2010-01-01\", \"2020-12-31\")).isel(lat=100, lon=150).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray under the hood used the `matplotlib` library. Any argument that goes into matplotlib can be passed to xarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.sel(time=slice(\"2010-01-01\", \"2020-12-31\")).isel(lat=100, lon=150).plot.line(\"-*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.sel(time=slice(\"2010-01-01\", \"2020-12-31\")).isel(lat=100, lon=150).plot(\n",
    "    aspect=2, size=3\n",
    ")\n",
    "plt.title(\"Temperature at 100N, 150E\")\n",
    "plt.xlabel(\"Monthly Time\")\n",
    "plt.ylabel(\"Temperature (K)\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two dimensional plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray is smart enough that in many cases it can interpret your data and choose an appropriate type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.isel(time=0).plot(robust=True, cbar_kwargs={\"label\": \"Temperature (°C)\"})\n",
    "plt.title(\"Temperature in January 1948\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faceting\n",
    "\n",
    "Its handy when we want to plot multiple plots along a dimension (e.g. time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_sub = ta.sel(time=slice(\"2010-01-01\", \"2010-06-30\"))\n",
    "ta_sub.plot(col=\"time\", col_wrap=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More advanced plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general the xarray basic plotting is great for data exploration (quick test).\n",
    "\n",
    "However, it other more plotting packages were integrated with xarray to produce more complicated plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example code below is how to plot it in various projections, adding coastlines etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "p = ta.isel(time=10).plot(\n",
    "    subplot_kws=dict(projection=ccrs.Orthographic(-80, 35), facecolor=\"gray\"),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    robust=True,\n",
    ")\n",
    "\n",
    "p.axes.coastlines()\n",
    "p.axes.add_feature(cfeature.BORDERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different projections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ta.isel(time=10).plot(\n",
    "    subplot_kws=dict(projection=ccrs.Robinson(), facecolor=\"gray\"),\n",
    "    figsize=(10, 5),\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    robust=True,\n",
    ")\n",
    "\n",
    "p.axes.coastlines()\n",
    "p.axes.add_feature(cfeature.BORDERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hover your mouse over the plot to see the temperature at different locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray\n",
    "ta.isel(time=10).hvplot(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    cmap=\"fire\",\n",
    "    projection=ccrs.Mollweide(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may run into issue with the next interactive figure, if you do, you can upgrade the ipywidgets library using the following command:\n",
    "\n",
    "python -m pip install --upgrade ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a simple animations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade ipywidgets\n",
    "ta.isel(time=range(12)).hvplot(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    cmap=\"fire\",\n",
    "    # projection=ccrs.Orthographic(-90, 30),\n",
    "    coastline=True,\n",
    "    groupby=\"time\",\n",
    "    widget_type=\"scrubber\",\n",
    "    widget_location=\"bottom\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray integrates seamlessly with NumPy, allowing you to apply many familiar NumPy functions directly to xarray objects (DataArrays and Datasets) while preserving their labeled structure and coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example let calculate log and sin of the air temprature, whatever they mean!\n",
    "ta_sel = ta.sel(time=\"2023-08-01\")\n",
    "\n",
    "log_ta = np.log(ta_sel)\n",
    "sin_ta = np.sin(ta_sel)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6))\n",
    "log_ta.plot(ax=axes[0])\n",
    "sin_ta.plot(ax=axes[1])\n",
    "\n",
    "axes[0].set_title(\"Log of Air Temperature!\")\n",
    "axes[1].set_title(\"Sine of Air Temperature!\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operation on two DataArrays\n",
    "ta_sum = ta_sel + ta_sel\n",
    "ta_sum.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use `isnull()`, `notnull()`, `fillna()`, `dropna()` and a few more to deal with missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot grids where it is `NaN` and its not `NaN`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "ta_sel.isnull().plot()\n",
    "plt.subplot(1, 2, 2)\n",
    "ta_sel.notnull().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the missing values with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_sel.fillna(0).plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the mean/max/min etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_sel_mean = ta_sel.mean()\n",
    "ta_sel_mean\n",
    "# Try to sum, std, min, max, median, quantile, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including labels (dimensions) in our calculations.\n",
    "\n",
    "For example we can take the mean over lat and lon dimensions to get the global mean of temperature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_mean = ta.mean(dim=[\"lat\", \"lon\"])\n",
    "ta_mean.sel(time=slice(\"2020-01-01\", \"2022-12-01\")).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: plot the map of global temp mean from the year 1990 to 2010\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta.sel(time=slice(\"1990-01-01\", \"2010-12-01\")).mean(dim=\"time\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning and grouping data using `groupby` and `resample`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_group = ta.groupby(\"time.year\").mean()\n",
    "ta_resample = ta.resample(time=\"Y\").mean()\n",
    "# Notice the dimension of the DataArray is now year instead of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "<u>Grouping</u>:\n",
    "\n",
    "- Uses the groupby function to group the data by the \"year\" component of the \"time\" coordinate. Each group represents a year's worth of data.\n",
    "- The `mean()` function is then applied within each group, calculating the average value for each year.\n",
    "- Flexibility: This method offers more flexibility if you need to perform different operations on each year's data (e.g., standard deviation, percentiles). You can iterate over the groups or apply further calculations within the groupby object.\n",
    "\n",
    "<u>Resampling</u>:\n",
    "\n",
    "- Uses the resample function to directly change the sampling frequency of the data to \"Y\" (yearly). This essentially averages all values within each year automatically.\n",
    "- For simple calculations like computing averages, this approach can be more efficient because it avoids explicit grouping and iteration.\n",
    "- Applying further operations on individual years requires additional steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate moving average:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_ta = ta.groupby(\"time.year\").mean()  # Group the data by year\n",
    "window_size = 3  # Define the window size for the moving average\n",
    "\n",
    "# # Calculate the moving average\n",
    "moving_avg = annual_ta.rolling(year=window_size, center=True).mean()\n",
    "\n",
    "moving_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of moving average\n",
    "\n",
    "# your codes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to resample the data to a different time frequency?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta_resample = ta.resample(time=\"5Y\").mean(dim=\"time\")\n",
    "ta_resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a costume function to the data along dimension(s)\n",
    "\n",
    "Xarray's `apply_ufunction()` is great for applying your costume functions along any dimension of your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate the trend in annual temperature:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to compute a linear trend of a time series (we use numpy.polyfit())\n",
    "def linear_trend(y):\n",
    "    if np.isnan(y).any():\n",
    "        return np.nan\n",
    "    x = np.arange(len(y))\n",
    "    pf = np.polyfit(x, y, 1)\n",
    "    # need to return an xr.DataArray for groupby\n",
    "    return pf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annual mean\n",
    "ta_annual = ta.resample(time=\"Y\").mean()\n",
    "# Calculate the linear trend\n",
    "trend_result = xr.apply_ufunc(\n",
    "    linear_trend,  # The function to apply (linear_trend in this case)\n",
    "    ta_annual,  # The input data (ta_annual in this case)\n",
    "    input_core_dims=[\n",
    "        [\"time\"]\n",
    "    ],  # Specifies the core dimensions of the input data (in this case, \"time\" is the core dimension)\n",
    "    vectorize=True,  # Vectorize the function (apply element-wise operations)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the trend resutls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_result.plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Calculating Annual Summer Temperature Anomaly\n",
    "\n",
    "#### Objective:\n",
    "\n",
    "To calculate the annual summer temperature anomaly for the entire time period and to visualize the anomaly trend and anomaly map for the year 2023.\n",
    "\n",
    "#### Hint:\n",
    "\n",
    "A simple index for anomaly is to subtract the long term mean from data.\n",
    "\n",
    "#### Procedure:\n",
    "\n",
    "1. **Summer Month Mask:**\n",
    "\n",
    "   - Create a mask for summer months (June, July, August) using `ta['time.month']` and `&`.\n",
    "\n",
    "2. **Apply Mask:**\n",
    "\n",
    "   - Apply the mask to select only summer months using `ta.where(mask)`. Note: Use the argument `drop=True` in `where()` to exclude months other than summer.\n",
    "\n",
    "3. **Calculate Climatological Mean:**\n",
    "\n",
    "   - Compute the climatological mean of summer temperatures (i.e., annual mean). Use `groupby()`\n",
    "\n",
    "4. **Calculate Anomalies:**\n",
    "\n",
    "   - Determine anomalies by subtracting the climatological mean from the summer temperature data.\n",
    "\n",
    "5. **Visualization:**\n",
    "   - Plot the anomaly for the year 2023 and the global mean (`mean[\"lat\",\"lon\"]`) for the entire time period. Utilize `matplotlib.subplot()` to display them side-by-side.\n",
    "\n",
    "#### Note:\n",
    "\n",
    "Keep an eye out for any unusual patterns or trends in the anomalies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Calculate the summer anomaly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mask for summer months (June, July, August)\n",
    "mask = (ta[\"time.month\"] >= 6) & (ta[\"time.month\"] <= 8)\n",
    "\n",
    "# Apply the mask to select only summer months data\n",
    "ta_summer = ta.where(mask, drop=True)\n",
    "\n",
    "# Calculate the annual mean of summer temperatures\n",
    "ta_summer_annual = ta_summer.groupby(\"time.year\").mean()\n",
    "\n",
    "# Calculate the climatological mean of summer temperatures\n",
    "clima_mean = ta_summer_annual.mean(dim=\"year\")\n",
    "\n",
    "# Calculate the summer temperature anomalies by subtracting the climatological mean\n",
    "summer_anomalies = ta_summer_annual - clima_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Plot the anomaly trend and anomaly map for the year 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 4))\n",
    "\n",
    "# Plot the summer anomalies for the year 2023\n",
    "summer_anomalies.sel(year=2023).plot(robust=True, cmap=\"coolwarm\", ax=axs[0])\n",
    "\n",
    "# Plot the global mean of summer temperature anomalies\n",
    "summer_anomalies.mean([\"lat\", \"lon\"]).plot(ax=axs[1])\n",
    "\n",
    "# Add an arrow pointing to the anomaly values in the year 2021\n",
    "axs[1].annotate(\n",
    "    \"Approaching values projected for 2100 :(\",\n",
    "    xy=(2023, summer_anomalies.sel(year=2023).mean([\"lat\", \"lon\"])),\n",
    "    xytext=(1960, summer_anomalies.sel(year=2023).mean([\"lat\", \"lon\"]) - 0.5),\n",
    "    arrowprops=dict(facecolor=\"black\", arrowstyle=\"->\"),\n",
    ")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on 1.5 C and its importance in [IPCC report: chapter 1](https://www.ipcc.ch/sr15/chapter/chapter-1/).\n",
    "\n",
    "P.S. To be more accurate we need to do a bit more:\n",
    "\n",
    "- We need to take the area of cells into account when calculating the global mean.\n",
    "- We need to deal with outliers.\n",
    "- This dataset is one of the many, other datasets may show different results.\n",
    "- And anomalies are not distributed uniformly, for example arctic is warming twice as fast the rest of the world, as we have seen it in the last trend analyses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Data and Speed: The Next Challenge\n",
    "\n",
    "We've covered the basics of climate data processing in Python. Now, let's tackle the real challenges:\n",
    "\n",
    "1. **Out-of-memory data:** What happens when datasets are too large to fit in memory?\n",
    "2. **Speeding up computations:** How can we analyze data faster, especially with large datasets?\n",
    "\n",
    "In the next session, we'll introduce `Dask`, a powerful tool for handling these issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scaling with Dask\n",
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# Get the number of cores\n",
    "n_cores = multiprocessing.cpu_count()\n",
    "# Specify the number of threads per worker\n",
    "threads_per_worker = 2  # adjust this based on your workload\n",
    "\n",
    "client = Client(n_workers=n_cores, threads_per_worker=threads_per_worker)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with a simple example of a 2D array of numbers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1000, 4000)\n",
    "ones_np = np.ones(shape)\n",
    "print(\"Size:\", ones_np.nbytes / 1e6, \"MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an equivalent Dask array using dask.array.ones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_da = dask.array.ones(shape)\n",
    "ones_da\n",
    "\n",
    "# Note: 1 MiB = 1,048,576 bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have not \"chunk\" the data yet. There is only one chunk with same shape as our Array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets chunk the data into 1000 by 1000 blocks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_size = (1000, 1000)\n",
    "ones_da = dask.array.ones(shape, chunks=chunks_size)\n",
    "ones_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pay close attention to the chunks size and the memory usage.\n",
    "\n",
    "### Dask graph\n",
    "A Dask graph, often referred to as a Dask task graph or computation graph, represents the logical structure of a computation. In this graph, each node represents a task or operation, and the edges represent dependencies between these tasks.\n",
    "\n",
    "**Thus, note that Dask does not implement any computations until you explicitly request them. At this stage, Dask only graphs the \"workflow\" of all tasks you've asked it to perform for you.**\n",
    "\n",
    "You can utilize the dask.array.visualize() function to visualize the Dask graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you get error related to graphviz when plotting\n",
    "#!pip uninstall graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dask graph\n",
    "dask.visualize(ones_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to numpy, we can perform arithmetic operations on dask arrays:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask is laze, it graphs the tasks but not doing it\n",
    "ones_mean = ones_da.mean()\n",
    "ones_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key distinction between Dask and NumPy lies in Dask's \"lazy\" evaluation approach, where computations are deferred until explicitly requested.\n",
    "\n",
    "The provided code represents merely the computation graph, outlining the sequence of operations, rather than executing the computations themselves:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(ones_da.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the mean, we can use the .compute() method to trigger the computation and get the result as a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate\n",
    "ones_mean.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize the calculation\n",
    "\n",
    "Now we know about chunking, what about parallel computing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is designed to take precisely 4 seconds when executed sequentially:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def inc(x):\n",
    "    # Takes two seconds to compute\n",
    "    time.sleep(2)\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def dec(y):\n",
    "    # Takes one second to compute\n",
    "    time.sleep(1)\n",
    "    return y - 1\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    # Takes one seconds to compute\n",
    "    time.sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = inc(1)\n",
    "y = dec(2)\n",
    "z = add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with dask.delayed we can make the above computation lazy. Meaning we only design the computation graph but not doing the computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = dask.delayed(inc)\n",
    "dec = dask.delayed(dec)\n",
    "add = dask.delayed(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x = inc(1)\n",
    "y = dec(2)\n",
    "z = add(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how fast the cell runs! This is because the dask.delayed calls are building up a task graph, but not actually executing it.\n",
    "\n",
    "Lets visualize the computation graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dask graph for calculation of z\n",
    "z.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your guess for the time it will take to compute z?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask-Xarray for Large-Scale Gridded Geospatial Data Analysis\n",
    "\n",
    "You've already explored the individual strengths of Xarray and Dask - the former providing a familiar and intuitive interface for labeled arrays, and the latter unlocking parallel processing on massive datasets. Now, let's delve into the exciting stuff when they're combined:\n",
    "\n",
    "**Key Advantages:**\n",
    "\n",
    "- **Parallel Processing:** Dask distributes data and computations across multiple cores or worker processes, enabling significantly faster analysis on large datasets. Operations like aggregation, reshaping, and arithmetic leverage distributed computing power, drastically reducing analysis times.\n",
    "- **Lazy Evaluation:** Dask-Xarray adopts a \"lazy\" approach, deferring actual computations until absolutely necessary.\n",
    "  - This optimizes resource utilization by focusing only on the required parts of complex workflows, further boosting efficiency.\n",
    "  - Reproducibility of the research. Computation the metadata than the data is more transferable, especially if the metadata is the same across datasets (e.g. STAC)\n",
    "- **Streaming:** For datasets exceeding disk capacity, Dask-Xarray employs streaming to process data in chunks, eliminating the need to load everything at once.\n",
    "- **Familiar API:** Xarray's intuitive API, reminiscent of NumPy and pandas, ensures a consistent experience regardless of data location: in-memory arrays or out-of-memory Dask arrays. This minimizes the learning curve and simplifies code adaptation.\n",
    "- **Flexibility:** Dask-Xarray adapts to your hardware and software environment, whether you're working on a single workstation, multi-core machine, cluster, or cloud platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! now we know how to use Dask to scale our computation. Let's go back to our air temprature dataset and see how we can use Dask to scale our computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just open the DataArrays it will be loaded into memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.open_dataarray(\"air.mon.mean.nc\")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is huge then this approach fails! so we need to use `chunks` (remember from dask) argument to load the data in chunks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the air temprature Dataset with Dask enabled\n",
    "da = xr.open_dataarray(\n",
    "    \"air.mon.mean.nc\",\n",
    "    chunks={\n",
    "        \"time\": 100,\n",
    "        \"lat\": \"auto\",\n",
    "        \"lon\": \"auto\",\n",
    "    },\n",
    ")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data has been loaded as a Dask array, with the chunks argument determining how the data is partitioned into manageable chunks.\n",
    "\n",
    "- This implies that the entire dataset is not loaded into memory; instead, a computational graph is constructed.\n",
    "- This graph consists of tasks that are executed on-demand, following a \"lazy\" evaluation strategy similar to the example demonstrated at the beginning of the session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from the dataset there are two ways:\n",
    "\n",
    "1. `.data` which returns a dask array\n",
    "2. `.to_numpy` and `.values`, which means it will call the `compute()`\n",
    "\n",
    "- Use `.to_numpy` instead of `.values` as it retruns more generlizable array (e.g. sparse arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data is a dask array and lazy!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the numpy array use `.to_numpy()` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = da.to_numpy()\n",
    "print(type(data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't worry about the nans, this is land temperature data and it is expected to have nans over the ocean and other places.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the computation on xarray when calling chunks is lazy.\n",
    "\n",
    "It means that the actual computation is deferred until it is explicitly needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do an example of a simple calculation with Dask-xarray by taking the mean:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = da.mean()\n",
    "std = da.std()\n",
    "mean_std = mean + std\n",
    "mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note its fast since its a lazy computation ---> no actual computation is done.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the dask graph for this calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(mean_std, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to perform the computation:\n",
    "\n",
    "1. `.compute()`: returns an xarray object. Recommended for smaller datasets where outputs are small enough to fit into memory.\n",
    "2. `.load()`: similar to compute but returns a dask object. (Not generally recommended for out-of-memory situations).\n",
    "3. `.persist():` does the computation but holds the results in the distributed cluster memory. Most common for out-of-memory situations but it requires access to clusters/clouds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_calculated = mean_std.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now dask is executing the graph and calculating the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_std.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the trend but with Dask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_annual = da.resample(time=\"Y\").mean()\n",
    "da_annual = da_annual.chunk(dict(time=-1))\n",
    "da_annual = da_annual.chunk({\"lat\": 100, \"lon\": 100, \"time\": -1})\n",
    "da_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that calculates the linear trend using numpy polyfit\n",
    "def linear_trend(y):\n",
    "    # y is the variable of interest\n",
    "    # Check if there is any NaN in y\n",
    "    if np.any(np.isnan(y)):\n",
    "        # Return NaN as slope\n",
    "        return np.nan\n",
    "    else:\n",
    "        # Create an array of indices as x\n",
    "        x = np.arange(len(y))\n",
    "        # Return only the slope of the linear fit\n",
    "        return np.polyfit(x, y, 1)[0]\n",
    "\n",
    "\n",
    "trend = xr.apply_ufunc(\n",
    "    linear_trend,\n",
    "    da_annual.variable,\n",
    "    input_core_dims=[[\"time\"]],\n",
    "    output_core_dims=[[]],\n",
    "    vectorize=True,\n",
    "    dask=\"parallelized\",\n",
    "    output_dtypes=[float],\n",
    ")\n",
    "trend_dataarray = xr.DataArray(\n",
    "    trend, dims=[\"lat\", \"lon\"], coords={\"lat\": ds.lat, \"lon\": ds.lon}\n",
    ")\n",
    "trend_dataarray.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import optimize\n",
    "\n",
    "(optimized,) = optimize(trend.data)\n",
    "optimized.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Dask to parallelize computations, there can be overhead associated with parallelization, chunking, and data movement between workers. In some cases, for smaller datasets, the overhead of parallelization can outweigh the benefits of parallel processing, resulting in longer execution times compared to a non-parallelized approach.\n",
    "\n",
    "In this specific case, with a small array (77 time steps, 360 latitudes, and 720 longitudes), the overhead introduced by Dask's parallelization may dominate the computation time. Dask is designed to handle larger-than-memory datasets efficiently by breaking them into smaller chunks and processing them in parallel. However, for smaller datasets that can fit into memory, the overhead of parallelization may outweigh the benefits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real out-of-memory-example:\n",
    "\n",
    "**Do not try to visualize! Its too big and will fail**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size is: 64.0 GB! To big to fit in memory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 59.60 GiB </td>\n",
       "                        <td> 7.63 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (200000, 40000) </td>\n",
       "                        <td> (1000, 1000) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8000 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"92\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"42\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"42\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"42\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"42\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"42\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"42\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"42\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"42\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"42\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"42\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"42\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"42\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"42\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"42\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"42\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"42\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"42\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"42\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"42\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"42\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"2\" y1=\"0\" x2=\"2\" y2=\"120\" />\n",
       "  <line x1=\"4\" y1=\"0\" x2=\"4\" y2=\"120\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"120\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"120\" />\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"120\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"16\" y2=\"120\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"120\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"120\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"120\" />\n",
       "  <line x1=\"28\" y1=\"0\" x2=\"28\" y2=\"120\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"120\" />\n",
       "  <line x1=\"32\" y1=\"0\" x2=\"32\" y2=\"120\" />\n",
       "  <line x1=\"34\" y1=\"0\" x2=\"34\" y2=\"120\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"120\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"38\" y2=\"120\" />\n",
       "  <line x1=\"42\" y1=\"0\" x2=\"42\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 42.00989029700999,0.0 42.00989029700999,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"21.004945\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >40000</text>\n",
       "  <text x=\"62.009890\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,62.009890,60.000000)\">200000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<ones_like, shape=(200000, 40000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigshape = (200000, 40000)\n",
    "chunk_shape = (1000, 1000)  # define your chunk shape\n",
    "big_ones = dask.array.ones(bigshape, chunks=chunk_shape)\n",
    "print(\"Size is:\", big_ones.nbytes/1e9, \"GB! To big to fit in memory\")\n",
    "big_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a fake xarray object and give it fake lat and lon ( in real world this big data could be your geospatial satellite/climate data).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;big_ones&#x27; (lat: 200000, lon: 40000)&gt;\n",
       "dask.array&lt;ones_like, shape=(200000, 40000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray&gt;\n",
       "Coordinates:\n",
       "  * lat      (lat) int64 0 1 2 3 4 5 ... 199995 199996 199997 199998 199999\n",
       "  * lon      (lon) int64 0 1 2 3 4 5 6 ... 39994 39995 39996 39997 39998 39999\n",
       "Attributes:\n",
       "    units:    m</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'big_ones'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>lat</span>: 200000</li><li><span class='xr-has-index'>lon</span>: 40000</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-74e948e0-796a-42e2-aeae-5fef193863a3' class='xr-array-in' type='checkbox' checked><label for='section-74e948e0-796a-42e2-aeae-5fef193863a3' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>dask.array&lt;chunksize=(1000, 1000), meta=np.ndarray&gt;</span></div><div class='xr-array-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table style=\"border-collapse: collapse;\">\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 59.60 GiB </td>\n",
       "                        <td> 7.63 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (200000, 40000) </td>\n",
       "                        <td> (1000, 1000) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Dask graph </th>\n",
       "                        <td colspan=\"2\"> 8000 chunks in 1 graph layer </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Data type </th>\n",
       "                        <td colspan=\"2\"> float64 numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"92\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"42\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"42\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"42\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"42\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"42\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"42\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"42\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"43\" x2=\"42\" y2=\"43\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"42\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"42\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"42\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"42\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"42\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"81\" x2=\"42\" y2=\"81\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"42\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"42\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"100\" x2=\"42\" y2=\"100\" />\n",
       "  <line x1=\"0\" y1=\"106\" x2=\"42\" y2=\"106\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"42\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"42\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"2\" y1=\"0\" x2=\"2\" y2=\"120\" />\n",
       "  <line x1=\"4\" y1=\"0\" x2=\"4\" y2=\"120\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"120\" />\n",
       "  <line x1=\"8\" y1=\"0\" x2=\"8\" y2=\"120\" />\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"120\" />\n",
       "  <line x1=\"14\" y1=\"0\" x2=\"14\" y2=\"120\" />\n",
       "  <line x1=\"16\" y1=\"0\" x2=\"16\" y2=\"120\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"120\" />\n",
       "  <line x1=\"22\" y1=\"0\" x2=\"22\" y2=\"120\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"120\" />\n",
       "  <line x1=\"26\" y1=\"0\" x2=\"26\" y2=\"120\" />\n",
       "  <line x1=\"28\" y1=\"0\" x2=\"28\" y2=\"120\" />\n",
       "  <line x1=\"30\" y1=\"0\" x2=\"30\" y2=\"120\" />\n",
       "  <line x1=\"32\" y1=\"0\" x2=\"32\" y2=\"120\" />\n",
       "  <line x1=\"34\" y1=\"0\" x2=\"34\" y2=\"120\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"120\" />\n",
       "  <line x1=\"38\" y1=\"0\" x2=\"38\" y2=\"120\" />\n",
       "  <line x1=\"42\" y1=\"0\" x2=\"42\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 42.00989029700999,0.0 42.00989029700999,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"21.004945\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >40000</text>\n",
       "  <text x=\"62.009890\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,62.009890,60.000000)\">200000</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></div></li><li class='xr-section-item'><input id='section-a68496e7-e0d9-48ae-9185-ec4e3e94b5a4' class='xr-section-summary-in' type='checkbox'  checked><label for='section-a68496e7-e0d9-48ae-9185-ec4e3e94b5a4' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lat</span></div><div class='xr-var-dims'>(lat)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 ... 199997 199998 199999</div><input id='attrs-86c412da-d9ec-4212-95d7-7353d33fe066' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-86c412da-d9ec-4212-95d7-7353d33fe066' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-70a6360a-b98a-4243-a32d-f83473060613' class='xr-var-data-in' type='checkbox'><label for='data-70a6360a-b98a-4243-a32d-f83473060613' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([     0,      1,      2, ..., 199997, 199998, 199999])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>lon</span></div><div class='xr-var-dims'>(lon)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>0 1 2 3 ... 39996 39997 39998 39999</div><input id='attrs-0c7ce0a7-764b-4e77-b190-d3f1c3e5c4a0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-0c7ce0a7-764b-4e77-b190-d3f1c3e5c4a0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b96902ab-4f43-450d-8a94-c75cd6b23162' class='xr-var-data-in' type='checkbox'><label for='data-b96902ab-4f43-450d-8a94-c75cd6b23162' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([    0,     1,     2, ..., 39997, 39998, 39999])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6713136e-7205-4298-a318-3f92739a2c19' class='xr-section-summary-in' type='checkbox'  ><label for='section-6713136e-7205-4298-a318-3f92739a2c19' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>lat</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-a762298a-a89d-4087-b0aa-8866a8b62a71' class='xr-index-data-in' type='checkbox'/><label for='index-a762298a-a89d-4087-b0aa-8866a8b62a71' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([     0,      1,      2,      3,      4,      5,      6,      7,      8,\n",
       "            9,\n",
       "       ...\n",
       "       199990, 199991, 199992, 199993, 199994, 199995, 199996, 199997, 199998,\n",
       "       199999],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;lat&#x27;, length=200000))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>lon</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-9cfe6c63-8088-4655-9076-fc36529e1773' class='xr-index-data-in' type='checkbox'/><label for='index-9cfe6c63-8088-4655-9076-fc36529e1773' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "       ...\n",
       "       39990, 39991, 39992, 39993, 39994, 39995, 39996, 39997, 39998, 39999],\n",
       "      dtype=&#x27;int64&#x27;, name=&#x27;lon&#x27;, length=40000))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-50e1ee23-5d68-422f-a371-a2aef33bcfe0' class='xr-section-summary-in' type='checkbox'  checked><label for='section-50e1ee23-5d68-422f-a371-a2aef33bcfe0' class='xr-section-summary' >Attributes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>m</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'big_ones' (lat: 200000, lon: 40000)>\n",
       "dask.array<ones_like, shape=(200000, 40000), dtype=float64, chunksize=(1000, 1000), chunktype=numpy.ndarray>\n",
       "Coordinates:\n",
       "  * lat      (lat) int64 0 1 2 3 4 5 ... 199995 199996 199997 199998 199999\n",
       "  * lon      (lon) int64 0 1 2 3 4 5 6 ... 39994 39995 39996 39997 39998 39999\n",
       "Attributes:\n",
       "    units:    m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_ones_xr = xr.DataArray(big_ones,dims=['lat', 'lon'], \n",
    "                           coords={'lat': np.arange(bigshape[0]), \n",
    "                                   'lon': np.arange(bigshape[1])}, \n",
    "                                   name='big_ones', \n",
    "                                   attrs={'units': 'm'})\n",
    "big_ones_xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do big calculations with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mean = big_ones.mean()+big_ones.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "with ProgressBar():\n",
    "    result = big_mean.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice:\n",
    "\n",
    "- Try to chunk the data along the time dimension and calculate the linear trend using the apply_ufunc function. What do you observe?\n",
    "- Also experiement with different lat and lon chunk sizes and examine the difference in execution time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close Dask client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data from Microsoft Planetary Computer\n",
    "\n",
    "The [Microsoft Planetary Computer](https://planetarycomputer.microsoft.com/) is a powerful cloud platform specifically designed for researchers in climate and environmental fields. It provides **unprecedented access to a vast repository of data**, including:\n",
    "\n",
    "- **Climate observations**\n",
    "- **Satellite imagery**\n",
    "- **Model outputs**\n",
    "\n",
    "The Planetary Computer leverages the **STAC API (SpatioTemporal Asset Catalog)**, a standardized interface that makes it easy to discover, search, and access datasets based on specific criteria like location, time period, and data type.\n",
    "\n",
    "**Here's a quick overview of the process:**\n",
    "\n",
    "**1. Explore the Data Catalog:** Browse the Planetary Computer's extensive collection of datasets through the user-friendly Data Catalog. Filter by parameters like spatial coverage, temporal resolution, and data type to find the resources relevant to your research.\n",
    "\n",
    "**2. Utilize the STAC API:** Interact with the data programmatically using the STAC API. This protocol enables flexible querying, subsetting, and retrieval of specific data segments you need for your analysis.\n",
    "\n",
    "**3. Download or Process Data:** Download the retrieved data directly to your local machine or leverage cloud-based processing environments within the Planetary Computer platform.\n",
    "\n",
    "**Additional Resources:**\n",
    "\n",
    "- **[Official Documentation](https://planetarycomputer.microsoft.com/docs/overview/about)** .\n",
    "- **[Catalog](https://planetarycomputer.microsoft.com/catalog)**\n",
    "- **[Community](https://github.com/microsoft/PlanetaryComputer)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac-client planetary-computer odc.stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "import planetary_computer\n",
    "import odc.stac\n",
    "import matplotlib.pyplot as plt\n",
    "from pystac.extensions.eo import EOExtension as eo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the data, we’ll create a pystac_client.Client. We’ll explain the modifier part later on, but it’s what lets us download the data assets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "    modifier=planetary_computer.sign_inplace,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define area of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_of_interest = [-122.001, 47, -122, 47.001]\n",
    "time_of_interest = \"2021-01-01/2021-12-31\"\n",
    "# area_of_interest = {\"type\": \"Point\", \"coordinates\": [-122.2751, 47.5469]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the catalog for the landsat data collection 2 for the year 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = catalog.search(\n",
    "    collections=[\"landsat-c2-l2\"],\n",
    "    # intersects=area_of_interest,\n",
    "    bbox=bbox_of_interest,\n",
    "    datetime=time_of_interest,\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 10}},\n",
    ")\n",
    "\n",
    "items = search.item_collection()\n",
    "print(f\"Returned {len(items)} Items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect one item to see what it looks like\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(items)\n",
    "items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data where each item is a time step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "bands_of_interest = [\"nir08\"]\n",
    "data_list = []\n",
    "\n",
    "for item in items:\n",
    "    data = odc.stac.stac_load(\n",
    "        [item], bands=bands_of_interest, bbox=bbox_of_interest\n",
    "    ).isel(time=0)\n",
    "    data_list.append(data)\n",
    "\n",
    "combined_data = xr.concat(data_list, dim=\"item\")\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.nir08.mean([\"x\", \"y\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.nir08.mean(\"item\").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"nir08\"].plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
